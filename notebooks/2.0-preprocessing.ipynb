{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-25 18:21:03.409663: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/carolinajimenez/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/carolinajimenez/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/carolinajimenez/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standard library imports.\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# Third party imports.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProductFeaturesExtractor:\n",
    "    def __init__(self):\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.tfidf_vectorizer_title = TfidfVectorizer()\n",
    "        self.tfidf_vectorizer_description = TfidfVectorizer()\n",
    "        self.scaler = StandardScaler()\n",
    "        self.image_model = VGG16(weights='imagenet', include_top=False)\n",
    "\n",
    "    def preprocess_text(self, text):\n",
    "        text = text.lower()\n",
    "        words = word_tokenize(text)\n",
    "        filtered_words = [word for word in words if word not in self.stop_words]\n",
    "        lemmatized_words = [self.lemmatizer.lemmatize(word) for word in filtered_words]\n",
    "        return ' '.join(lemmatized_words)\n",
    "\n",
    "    def extract_text_features(self, titles, descriptions):\n",
    "        titles_processed = [self.preprocess_text(title) for title in titles]\n",
    "        descriptions_processed = [self.preprocess_text(description) for description in descriptions]\n",
    "        title_features = self.tfidf_vectorizer_title.fit_transform(titles_processed)\n",
    "        description_features = self.tfidf_vectorizer_description.fit_transform(descriptions_processed)\n",
    "        return title_features, description_features\n",
    "\n",
    "    def extract_image_features(self, img_paths):\n",
    "        image_features = []\n",
    "        for img_path in img_paths:\n",
    "            img = image.load_img(img_path, target_size=(224, 224))\n",
    "            img_array = image.img_to_array(img)\n",
    "            img_array = np.expand_dims(img_array, axis=0)\n",
    "            img_array = preprocess_input(img_array)\n",
    "            features = self.image_model.predict(img_array)\n",
    "            image_features.append(features.flatten())\n",
    "        return np.array(image_features)\n",
    "\n",
    "    def scale_features(self, features):\n",
    "        return self.scaler.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58889256/58889256 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Feature extractor instance creation\n",
    "feature_extractor = ProductFeaturesExtractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Preprocessing\n",
    "data['title'] = data['title'].apply(feature_extractor.preprocess_text)\n",
    "data['description'] = data['description'].apply(feature_extractor.preprocess_text)\n",
    "\n",
    "# Text Feature Extraction\n",
    "title_features, description_features = feature_extractor.extract_text_features(data['title'], data['description'])\n",
    "\n",
    "# Image Feature Extraction\n",
    "image_features = feature_extractor.extract_image_features(data['thumbnail'])\n",
    "\n",
    "# Price and Availability Feature Scaling\n",
    "price_availability_features = feature_extractor.scale_features(data[['price', 'availability']].values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
